GHG Emissions Analysis and Insights Agent
This project is a sophisticated, AI-powered agent designed to help companies analyze their greenhouse gas (GHG) emissions data. Built with Streamlit and powered by Google's Gemini models, this agent provides a conversational interface to query company emissions data, validate it against the GHG Protocol, and benchmark it against peers.

It uses a multi-tool, Retrieval-Augmented Generation (RAG) architecture to provide accurate, context-aware, and data-driven responses.

âœ¨ Features
The agent is equipped with a suite of specialized tools, and an intelligent router automatically selects the best tool (or combination of tools) to answer a user's query:

ğŸ“„ Protocol Q&A: Answers general knowledge questions about GHG accounting principles by searching the official GHG Protocol document.

âœ… Data Validation: Audits the company's emissions data (Scope 1, 2, and 3) against the GHG Protocol for correct classification and plausible emission factors.

ğŸ“Š Summary Reports: Generates flexible, high-level summary reports with key insights for all or specified emissions scopes.

â“ Text-to-SQL Analysis: Converts natural language questions into SQL queries to perform specific, granular calculations and aggregations on the company's data.

ğŸ†š Peer Comparison: Compares the company's emissions for any scope or sub-category against peer data extracted from PDF reports.

ğŸ§  Intelligent Fallback: Ensures a helpful response for ambiguous queries by searching all available data sources.

ğŸ“ Project Structure
The project is organized into the following directories and files:

.
â”œâ”€â”€ knowledge_base/
â”‚   â”œâ”€â”€ ghg-protocol-revised.pdf  # Knowledge base for Q&A and validation
â”‚   â”œâ”€â”€ peer1_emissions_report.pdf # (User-provided)
â”‚   â””â”€â”€ peer2_emissions_report.pdf # (User-provided)
â”‚
â”œâ”€â”€ emissions_data/
â”‚   â”œâ”€â”€ scope1.csv                # Company's Scope 1 data
â”‚   â”œâ”€â”€ scope2.csv                # Company's Scope 2 data
â”‚   â”œâ”€â”€ scope3.csv                # Company's Scope 3 data
â”‚   â”œâ”€â”€ peer1_data.csv            # (Generated by extractor script)
â”‚   â””â”€â”€ peer2_data.csv            # (Generated by extractor script)
â”‚
â”œâ”€â”€ app.py                        # The main Streamlit application file
â”œâ”€â”€ extract_peer_data.py          # One-time script to extract data from peer PDFs
â”œâ”€â”€ requirements.txt              # Python dependencies
â””â”€â”€ README.md                     # This file

ğŸš€ Getting Started
Follow these steps to set up and run the agent locally.

Prerequisites
Python 3.8 or higher

Access to the Google AI API (Gemini)

1. Setup
Create Project Directory: Create a new folder for the project and place app.py, extract_peer_data.py, and requirements.txt inside it.

Create Subdirectories: Inside the main project folder, create two subdirectories: knowledge_base and emissions_data.

Place Your Data:

Move your data files (ghg-protocol-revised.pdf, peer1_emissions_report.pdf, peer2_emissions_report.pdf) into the knowledge_base folder.

Move your company's emissions files (scope1.csv, scope2.csv, scope3.csv) into the emissions_data folder.

2. Installation
Install Dependencies: Open your terminal, navigate to the project folder, and install the required Python libraries:

pip install -r requirements.txt

Set API Key: You must set your Google Gemini API key as an environment variable.

macOS/Linux:

export GOOGLE_API_KEY="YOUR_API_KEY_HERE"

Windows (Command Prompt):

set GOOGLE_API_KEY="YOUR_API_KEY_HERE"

3. Usage
The application runs in two distinct steps: a one-time data extraction followed by the interactive web app.

Step 1: Extract Peer Data (One-Time Step)

Before launching the main app, you must first process the peer PDF reports. This script uses Gemini's vision capabilities to extract the relevant tables and save them as clean CSV files.

Run the script from your terminal:

python extract_peer_data.py

This will create peer1_data.csv and peer2_data.csv inside the emissions_data folder. You only need to run this again if your peer reports are updated.

Step 2: Launch the Analysis Agent

Once the peer data has been extracted, you can start the interactive Streamlit application.

streamlit run app.py

Your default web browser will open with the agent's user interface, ready for you to ask questions.